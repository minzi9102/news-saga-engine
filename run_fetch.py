# run_fetch.py
import asyncio
import sys
from src.date_utils import get_target_date_str
from src.crawler import CrawlerService
from src.archiver import DataArchiver

async def main():
    # 1. ç¡®å®šç›®æ ‡æ—¥æœŸ
    date_str = get_target_date_str()
    print(f"=== ğŸ“¥ å¯åŠ¨æ•°æ®é‡‡é›† (Fetch): {date_str} ===")
    
    # 2. çˆ¬å–æ•°æ® (Crawl)
    crawler = CrawlerService()
    briefing = await crawler.fetch_daily_briefing(date_str)
    
    if not briefing or not briefing.news_items:
        print(f"âŒ é‡‡é›†å¤±è´¥æˆ–å½“æ—¥({date_str})æ— æ–°é—»å†…å®¹")
        # è¿”å›éé›¶çŠ¶æ€ç ï¼Œä»¥ä¾¿ CI/CD çŸ¥é“è¿™æ­¥å¤±è´¥äº†ï¼Œåœæ­¢åç»­æ­¥éª¤
        sys.exit(1)

    print(f"âœ… é‡‡é›†å®Œæˆï¼Œå…±æŠ“å– {len(briefing.news_items)} æ¡æ–°é—» (å«å¿«è®¯å­æ¡ç›®)")

    # 3. å½’æ¡£åŸå§‹æ•°æ® (Archive)
    archiver = DataArchiver()
    saved_path = archiver.save_daily_raw(briefing)
    
    print(f"=== ğŸ“¥ é‡‡é›†ä»»åŠ¡ç»“æŸï¼Œæ•°æ®å·²ä¿å­˜è‡³: {saved_path} ===")

if __name__ == "__main__":
    asyncio.run(main())