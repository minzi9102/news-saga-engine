'''
FilePath: \news_crawl\run_report.py
'''
# run_report.py
import asyncio
import os
import sys
from dotenv import load_dotenv
from src.date_utils import get_target_date_str
from src.archiver import DataArchiver
from src.manager import SagaManager
from src.reporter import SagaReporter
from src.notifier import EmailNotifier

# åŠ è½½ç¯å¢ƒå˜é‡ (API Key, SMTP Config)
load_dotenv()

async def main():
    # 1. ç¡®å®šç›®æ ‡æ—¥æœŸ
    date_str = get_target_date_str()
    print(f"=== ğŸ“Š å¯åŠ¨æŠ¥å‘Šç”Ÿæˆ (Report): {date_str} ===")

    # 2. è¯»å–åŸå§‹æ•°æ® (Load)
    archiver = DataArchiver()
    try:
        briefing = archiver.load_daily_raw(date_str)
        print(f"âœ… æˆåŠŸåŠ è½½åŸå§‹æ¡£æ¡ˆï¼ŒåŒ…å« {len(briefing.news_items)} æ¡æ–°é—»")
    except FileNotFoundError:
        print(f"âŒ æœªæ‰¾åˆ°æ—¥æœŸ {date_str} çš„åŸå§‹æ¡£æ¡ˆï¼")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ 'python run_fetch.py' è·å–æ•°æ®ã€‚")
        sys.exit(1)

    # 3. è®¤çŸ¥å±‚å¤„ç† (AI Analysis & Saga Update)
    # æ³¨æ„ï¼šè¿™ä¸€æ­¥ä¼šè°ƒç”¨ LLM å¹¶æ›´æ–° data/sagas ä¸‹çš„ JSON æ–‡ä»¶
    print("\nğŸ§  è¿›å…¥è®¤çŸ¥å±‚å¤„ç† (Saga Analysis)...")
    manager = SagaManager()
    await manager.process_daily_briefing(briefing)

    # 4. ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š (Render)
    print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š...")
    reporter = SagaReporter()
    
    # A. ç”Ÿæˆ Markdown (ç”¨äº GitHub ä»“åº“å±•ç¤º)
    reporter.generate_readme("README.md", briefing=briefing)

    # B. ç”Ÿæˆ HTML (ç”¨äºé‚®ä»¶å’Œé™„ä»¶)
    html_content = reporter.generate_html_report("report.html", briefing=briefing)

    # 5. å‘é€é€šçŸ¥ (Notify)
    if os.getenv("ENABLE_EMAIL", "false").lower() == "true":
        print("\nğŸ“§ æ­£åœ¨å‘é€é‚®ä»¶é€šçŸ¥...")
        notifier = EmailNotifier()
        notifier.send_daily_report(date_str, html_content)
    else:
        print("\nğŸš« é‚®ä»¶å‘é€å·²ç¦ç”¨ (ENABLE_EMAIL != true)")

    print(f"=== ğŸ“Š æŠ¥å‘Šä»»åŠ¡å®Œæˆ ===")

if __name__ == "__main__":
    asyncio.run(main())